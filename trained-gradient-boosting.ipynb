{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# import packages\nimport csv\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#read data\ntrain_features_data = pd.read_csv('../input/hr-dataset/train_LZdllcl.csv')\ntest_features_data = pd.read_csv('../input/hr-dataset/test_2umaH9m.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_data.drop(['employee_id'], axis=\"columns\", inplace=True)\ntrain_features_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Categorical Features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_fetaures_col = []\nfor column in train_features_data.columns:\n    if train_features_data[column].dtype == object:\n        cat_fetaures_col.append(column)\n        print(f\"{column} : {train_features_data[column].unique()}\")\n        print(train_features_data[column].value_counts())\n        print(\"-------------------------------------------\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Numerical Features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#numeric-cat ==> discrete\ndisc_feature_col = []\nfor column in train_features_data.columns:\n    if train_features_data[column].dtypes != object and train_features_data[column].nunique() <= 30:\n        print(f\"{column} : {train_features_data[column].unique()}\")\n        print(train_features_data[column].value_counts())\n        disc_feature_col.append(column)\n        print(\"-------------------------------------------\")\n        \ndisc_feature_col.remove('is_promoted')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cont_feature_col=[]\nfor column in train_features_data.columns:\n    if train_features_data[column].dtypes != object and train_features_data[column].nunique() > 30:\n        print(f\"{column} : Minimum: {train_features_data[column].min()}, Maximum: {train_features_data[column].max()}\")\n        cont_feature_col.append(column)\n        print(\"-------------------------------------------\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#there are missing values for \"education\" and \"previous_year_rating\" cols.\ntrain_features_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#eliminate null values(fill with mode of that column)\n\nfor column in train_features_data.columns:\n    train_features_data[column].fillna(train_features_data[column].mode()[0], inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_features_data['education'].mode()[0])\nprint(train_features_data['previous_year_rating'].mode()[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#there are no missing values in our dataset anymore!!!\ntrain_features_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#outlier analysis using box-plot(continuos data can have outliers(aykırı değerler))\n\nsns.set(style=\"whitegrid\",font_scale=1)\nplt.figure(figsize=(7,7))\nsns.boxplot(data=train_features_data[cont_feature_col])\nplt.xticks(rotation=30)\nplt.title(\"Box plot of continuos features\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# find the IQR\n\nq1 = train_features_data[cont_feature_col].quantile(.25)\nq3 = train_features_data[cont_feature_col].quantile(.75)\nIQR = q3-q1\n\nprint(\"         IQR\")\nprint(\"------------------------------\\n\")\nprint(IQR)\nprint(\"         q1\")\nprint(\"------------------------------\\n\")\nprint(q1)\nprint(\"         q3\")\nprint(\"------------------------------\\n\")\nprint(q3)\n\n\nlower_bound = q1 - 1.5*IQR\nupper_bound = q3 + 1.5*IQR\nprint(\"\\n--------lower bounds--------\")\nprint(lower_bound)\nprint(\"\\n--------upper bound---------\")\nprint(upper_bound)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(lower_bound)\nprint(\"-------------------\")\nprint(lower_bound[0])\nprint(lower_bound[1])\nprint(lower_bound[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outliers_df = np.logical_or((train_features_data[cont_feature_col] < lower_bound), (train_features_data[cont_feature_col] > upper_bound)) \noutliers_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outlier_total=[]\noutlier_percentage=[]\n\nfor col in list(train_features_data[cont_feature_col].columns):\n    try:\n        outlier_total.append(outliers_df[col].value_counts()[True])\n        outlier_percentage.append((outliers_df[col].value_counts()[True] / outliers_df[col].value_counts().sum())*100)\n    except:\n        outlier_total.append(0)\n        outlier_percentage.append(0)\n        \nprint(outlier_total)\nprint(outlier_percentage)\n\noutlier_number_df=pd.DataFrame(zip(list(outliers_df.columns), outlier_total,outlier_percentage), columns=['name', 'total', 'outlier(%)'])\n#outlier_df.set_index('name', inplace=True)\noutlier_number_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outlier_det_age_df=train_features_data[cont_feature_col]['age']\nprint(type(outlier_det_age_df))\n\noutlier_det_los_df=train_features_data[cont_feature_col]['length_of_service']\noutlier_det_age_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(outlier_det_age_df.head())\nprint(outlier_det_los_df.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outlier_age=train_features_data[cont_feature_col]['age'] > upper_bound[0]\nprint(outlier_age.head())\n\noutlier_los=train_features_data[cont_feature_col]['length_of_service'] > upper_bound[1]\nprint(outlier_los.head())\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fill outliers with mean\n\noutlier_det_age_df[outlier_age]=upper_bound[0]\nprint(outlier_det_age_df[outlier_age])\n\nprint(\"=======================\")\noutlier_det_los_df[outlier_los]=upper_bound[1]\nprint(outlier_det_los_df[outlier_los])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#update original train set with fixed outlier values\n\ntrain_features_data['age']=outlier_det_age_df\ntrain_features_data['length_of_service']=outlier_det_los_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#there is NO outlier anymore!!!(see the boxplot)\n\nsns.set(style=\"whitegrid\",font_scale=1)\nplt.figure(figsize=(7,7))\nsns.boxplot(data=train_features_data[cont_feature_col])\nplt.xticks(rotation=30)\nplt.title(\"Box plot of continuos features\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#encode ediyoruzzz!!!\n\n#encoding categorical features (str-->float)\n\nfrom sklearn.preprocessing import OrdinalEncoder\nenc = OrdinalEncoder()\n\nenc.fit(train_features_data)\ntrain_features_data_arr=enc.transform(train_features_data)\n\ncol_names_list=train_features_data.columns\nencoded_categorical_df=pd.DataFrame(train_features_data_arr, columns=col_names_list)\n\n#check types\nencoded_categorical_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split df to X and Y\nfrom sklearn.model_selection import train_test_split\n\ny = encoded_categorical_df.loc[:, 'is_promoted'].values\nX = encoded_categorical_df.drop('is_promoted', axis=1)\n\n# split data into 80-20 for training set / test set\n#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y, random_state=100)\n\nX_train = X\ny_train = y\n\n\n#now, prepare the real test dataset to find preds and (to submit)\ntest_df = test_features_data.drop(['employee_id'], axis=1)\n\n#fillna test_df\nfor column in test_df.columns:\n    test_df[column].fillna(test_df[column].mode()[0], inplace=True)\n\n#fix outliers in test_df same as before(baskilama)\ntest_df['age'][test_df['age'] > upper_bound[0]] = upper_bound[0]\ntest_df['length_of_service'][test_df['length_of_service'] > upper_bound[1]]=upper_bound[1]\n\n#create dummy is_promoted in test_df to match column numbers (it will be removed again after encoding)\ntest_df[\"is_promoted\"] = 1\n\n#encode test_df\ntest_df_arr = enc.transform(test_df)\ntest_df_encoded = pd.DataFrame(test_df_arr, columns=col_names_list)\n\n# drop \"is_promoted\"\nX_test = test_df_encoded.drop('is_promoted', axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"binary_cols = [col for col in list(encoded_categorical_df.columns) if encoded_categorical_df[col].nunique() <= 2] \nbinary_cols.remove('is_promoted')\n\nnon_binary_cols = [col for col in list(encoded_categorical_df.columns) if encoded_categorical_df[col].nunique() > 2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#normalization(make all values bet. 0-1)\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nscaler.fit(X_train[non_binary_cols])\n\nX_train_normalized_arr=scaler.transform(X_train[non_binary_cols])\nX_train_normalized_df=pd.DataFrame(X_train_normalized_arr, columns=non_binary_cols)\n\nX_test_normalized_arr=scaler.transform(X_test[non_binary_cols])\nX_test_normalized_df=pd.DataFrame(X_test_normalized_arr, columns=non_binary_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train_normalized_df.head())\nprint(X_test_normalized_df.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_binary_cols_df = X_train[binary_cols]\nX_train_binary_cols_df.reset_index(inplace=True, drop=True)\n\nX_train_final_df = pd.concat([X_train_binary_cols_df,X_train_normalized_df], axis=1)\n\nX_train_final_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_binary_cols_df = X_test[binary_cols]\nX_test_binary_cols_df.reset_index(inplace=True, drop=True)\n\nX_test_final_df = pd.concat([X_test_binary_cols_df,X_test_normalized_df], axis=1)\n\nX_test_final_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#here is size of our train and test datasets\nprint(len(X_train_final_df))\nprint(len(X_test_final_df))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(y_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import necessary libraries\n\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score, roc_curve, confusion_matrix, classification_report, roc_auc_score\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cross-validation with 10 splits\ncv = StratifiedShuffleSplit(n_splits=10, random_state = 42, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# display test scores and return result string and indexes of false samples\ndef display_test_scores(test, pred):\n    str_out = \"\"\n    str_out += (\"TEST SCORES\\n\")\n    str_out += (\"=====================\\n\")\n    \n    #print accuracy\n    accuracy = accuracy_score(test, pred)\n    str_out += (\"ACCURACY: {:.4f}\\n\".format(accuracy))\n    str_out += (\"\\n\")\n    str_out += (\"--------------------\\n\")\n    \n\n    #print AUC score\n    auc = roc_auc_score(test, pred)\n    str_out += (\"AUC: {:.4f}\\n\".format(auc))\n    str_out += (\"\\n\")\n    str_out += (\"--------------------\\n\")\n\n    #print confusion matrix\n    str_out += (\"CONFUSION MATRIX:\\n\")\n    conf_mat = confusion_matrix(test, pred)\n    str_out += (\"{}\".format(conf_mat))\n    str_out += (\"\\n\")\n    str_out += (\"\\n\")\n    str_out += (\"--------------------\\n\")\n    \n    #print FP, FN\n    str_out += (\"FALSE POSITIVES:\\n\")\n    fp = conf_mat[1][0]\n    pos_labels = conf_mat[1][0]+conf_mat[1][1]\n    str_out += (\"{} out of {} positive labels ({:.4f}%)\\n\".format(fp, pos_labels,fp/pos_labels))\n    str_out += (\"\\n\")\n    str_out += (\"------------------------------------\\n\")\n\n    str_out += (\"FALSE NEGATIVES:\\n\")\n    fn = conf_mat[0][1]\n    neg_labels = conf_mat[0][1]+conf_mat[0][0]\n    str_out += (\"{} out of {} negative labels ({:.4f}%)\\n\".format(fn, neg_labels, fn/neg_labels))\n    str_out += (\"\\n\")\n    str_out += (\"------------------------------------\\n\")\n\n    #print classification report\n    str_out += (\"PRECISION, RECALL, F1 scores:\\n\\n\")\n    str_out += (\"{}\".format(classification_report(test, pred)))\n    \n    false_indexes = np.where(test != pred)\n    return str_out, false_indexes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train all dataset\n\n#Importing XGBM Classifier \nfrom sklearn.ensemble import GradientBoostingClassifier\n\n#creating an extreme Gradient boosting instance\ngbc = GradientBoostingClassifier(random_state=0, max_depth=5, max_features=None, n_estimators=100, subsample=1)\n\ngbc.fit(X_train_final_df, y_train)\n\n# prediction results\ny_pred = gbc.predict(X_test_final_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=y_pred.astype(int)\ntype(y_pred[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create output df\nemployee_ids = test_features_data[\"employee_id\"].values\noutput_df=pd.DataFrame(zip(employee_ids, y_pred), columns=[\"employee_id\", \"is_promoted\"])\n\n#create output csv file\noutput_df.to_csv('gradient_boosting_file.csv', index=False, sep=\",\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}