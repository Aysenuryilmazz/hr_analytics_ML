{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# import packages\nimport csv\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nimport seaborn as sns\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#read data\ntrain_features_data = pd.read_csv('../input/hr-dataset/train_LZdllcl.csv')\ntest_features_data = pd.read_csv('../input/hr-dataset/test_2umaH9m.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_features_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_data.drop(['employee_id'], axis=\"columns\", inplace=True)\ntrain_features_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_features_data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Categorical Features**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_fetaures_col = []\nfor column in train_features_data.columns:\n    if train_features_data[column].dtype == object:\n        cat_fetaures_col.append(column)\n        print(f\"{column} : {train_features_data[column].unique()}\")\n        print(train_features_data[column].value_counts())\n        print(\"-------------------------------------------\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Numerical Features**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#numeric-cat ==> discrete\ndisc_feature_col = []\nfor column in train_features_data.columns:\n    if train_features_data[column].dtypes != object and train_features_data[column].nunique() <= 30:\n        print(f\"{column} : {train_features_data[column].unique()}\")\n        print(train_features_data[column].value_counts())\n        disc_feature_col.append(column)\n        print(\"-------------------------------------------\")\n        \ndisc_feature_col.remove('is_promoted')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cont_feature_col=[]\nfor column in train_features_data.columns:\n    if train_features_data[column].dtypes != object and train_features_data[column].nunique() > 30:\n        print(f\"{column} : Minimum: {train_features_data[column].min()}, Maximum: {train_features_data[column].max()}\")\n        cont_feature_col.append(column)\n        print(\"-------------------------------------------\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#there are missing values for \"education\" and \"previous_year_rating\" cols.\ntrain_features_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#eliminate null values(fill with mode of that column)\n\nfor column in train_features_data.columns:\n    train_features_data[column].fillna(train_features_data[column].mode()[0], inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_features_data['education'].mode()[0])\nprint(train_features_data['previous_year_rating'].mode()[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#there are no missing values in our dataset anymore!!!\ntrain_features_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#there is no \"NaN\" values anymore\nprint(train_features_data['previous_year_rating'].unique())\nprint(train_features_data['education'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#outlier analysis using box-plot(continuos data can have outliers(aykırı değerler))\n\nsns.set(style=\"whitegrid\",font_scale=1)\nplt.figure(figsize=(7,7))\nsns.boxplot(data=train_features_data[cont_feature_col])\nplt.xticks(rotation=30)\nplt.title(\"Box plot of continuos features\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# find the IQR\n\nq1 = train_features_data[cont_feature_col].quantile(.25)\nq3 = train_features_data[cont_feature_col].quantile(.75)\nIQR = q3-q1\n\nprint(\"         IQR\")\nprint(\"------------------------------\\n\")\nprint(IQR)\nprint(\"         q1\")\nprint(\"------------------------------\\n\")\nprint(q1)\nprint(\"         q3\")\nprint(\"------------------------------\\n\")\nprint(q3)\n\n\nlower_bound = q1 - 1.5*IQR\nupper_bound = q3 + 1.5*IQR\nprint(\"\\n--------lower bounds--------\")\nprint(lower_bound)\nprint(\"\\n--------upper bound---------\")\nprint(upper_bound)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(lower_bound)\nprint(\"-------------------\")\nprint(lower_bound[0])\nprint(lower_bound[1])\nprint(lower_bound[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outliers_df = np.logical_or((train_features_data[cont_feature_col] < lower_bound), (train_features_data[cont_feature_col] > upper_bound)) \noutliers_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outlier_total=[]\noutlier_percentage=[]\n\nfor col in list(train_features_data[cont_feature_col].columns):\n    try:\n        outlier_total.append(outliers_df[col].value_counts()[True])\n        outlier_percentage.append((outliers_df[col].value_counts()[True] / outliers_df[col].value_counts().sum())*100)\n    except:\n        outlier_total.append(0)\n        outlier_percentage.append(0)\n        \nprint(outlier_total)\nprint(outlier_percentage)\n\noutlier_number_df=pd.DataFrame(zip(list(outliers_df.columns), outlier_total,outlier_percentage), columns=['name', 'total', 'outlier(%)'])\n#outlier_df.set_index('name', inplace=True)\noutlier_number_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outlier_det_age_df=train_features_data[cont_feature_col]['age']\nprint(type(outlier_det_age_df))\n\noutlier_det_los_df=train_features_data[cont_feature_col]['length_of_service']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outlier_det_age_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(outlier_det_age_df.head())\nprint(outlier_det_los_df.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outlier_age=train_features_data[cont_feature_col]['age'] > upper_bound[0]\nprint(outlier_age.head())\n\noutlier_los=train_features_data[cont_feature_col]['length_of_service'] > upper_bound[1]\nprint(outlier_los.head())\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(outlier_age.nunique())\nprint(outlier_age.value_counts())\n\nprint(outlier_los.value_counts())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fill outliers upper bound\n\noutlier_det_age_df[outlier_age]=upper_bound[0]\nprint(outlier_det_age_df[outlier_age])\n\nprint(\"=======================\")\noutlier_det_los_df[outlier_los]=upper_bound[1]\nprint(outlier_det_los_df[outlier_los])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#update original train set with fixed outlier values\n\ntrain_features_data['age']=outlier_det_age_df\ntrain_features_data['length_of_service']=outlier_det_los_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#there is NO outlier anymore!!!(see the boxplot)\n\nsns.set(style=\"whitegrid\",font_scale=1)\nplt.figure(figsize=(7,7))\nsns.boxplot(data=train_features_data[cont_feature_col])\nplt.xticks(rotation=30)\nplt.title(\"Box plot of continuos features\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\n#baskilama(if value>upper --> make value=upper OR value<lower --> make value=lower)\n\noutlier_det_age_df[outlier_age]=lower_bound[0]\noutlier_det_age_df[outlier_age]\n\n\"\"\"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#encode ediyoruzzz!!!\n\n#encoding categorical features (str-->float)\n\nfrom sklearn.preprocessing import OrdinalEncoder\nenc = OrdinalEncoder()\n\nenc.fit(train_features_data)\ntrain_features_data_arr=enc.transform(train_features_data)\n\ncol_names_list=train_features_data.columns\nencoded_categorical_df=pd.DataFrame(train_features_data_arr, columns=col_names_list)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check types\nencoded_categorical_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split df to X and Y\nfrom sklearn.model_selection import train_test_split\n\ny = encoded_categorical_df.loc[:, 'is_promoted'].values\nX = encoded_categorical_df.drop('is_promoted', axis=1)\n\n# split data into 80-20 for training set / test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y, random_state=100)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"binary_cols = [col for col in list(encoded_categorical_df.columns) if encoded_categorical_df[col].nunique() <= 2] \nbinary_cols.remove('is_promoted')\n\nnon_binary_cols = [col for col in list(encoded_categorical_df.columns) if encoded_categorical_df[col].nunique() > 2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#normalization(make all values bet. 0-1)\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nscaler.fit(X_train[non_binary_cols])\n\nX_train_normalized_arr=scaler.transform(X_train[non_binary_cols])\nX_train_normalized_df=pd.DataFrame(X_train_normalized_arr, columns=non_binary_cols)\n\nX_test_normalized_arr=scaler.transform(X_test[non_binary_cols])\nX_test_normalized_df=pd.DataFrame(X_test_normalized_arr, columns=non_binary_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_normalized_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_normalized_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_binary_cols_df = X_train[binary_cols]\nX_train_binary_cols_df.reset_index(inplace=True, drop=True)\n\nX_train_final_df = pd.concat([X_train_binary_cols_df,X_train_normalized_df], axis=1)\n\nX_train_final_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_binary_cols_df = X_test[binary_cols]\nX_test_binary_cols_df.reset_index(inplace=True, drop=True)\n\nX_test_final_df = pd.concat([X_test_binary_cols_df,X_test_normalized_df], axis=1)\n\nX_test_final_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#here is size of our train and test datasets\nprint(len(X_train_final_df))\nprint(len(X_test_final_df))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(y_train))\nprint(len(y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import necessary libraries\n\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score, roc_curve, confusion_matrix, classification_report, roc_auc_score\nfrom sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB, CategoricalNB\nfrom sklearn.svm import LinearSVC,SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cross-validation with 10 splits\ncv = StratifiedShuffleSplit(n_splits=10, random_state = 42, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# display test scores and return result string and indexes of false samples\ndef display_test_scores(test, pred):\n    str_out = \"\"\n    str_out += (\"TEST SCORES\\n\")\n    str_out += (\"=====================\\n\")\n    \n    #print accuracy\n    accuracy = accuracy_score(test, pred)\n    str_out += (\"ACCURACY: {:.4f}\\n\".format(accuracy))\n    str_out += (\"\\n\")\n    str_out += (\"--------------------\\n\")\n    \n\n    #print AUC score\n    auc = roc_auc_score(test, pred)\n    str_out += (\"AUC: {:.4f}\\n\".format(auc))\n    str_out += (\"\\n\")\n    str_out += (\"--------------------\\n\")\n\n    #print confusion matrix\n    str_out += (\"CONFUSION MATRIX:\\n\")\n    conf_mat = confusion_matrix(test, pred)\n    str_out += (\"{}\".format(conf_mat))\n    str_out += (\"\\n\")\n    str_out += (\"\\n\")\n    str_out += (\"--------------------\\n\")\n    \n    #print FP, FN\n    str_out += (\"FALSE POSITIVES:\\n\")\n    fp = conf_mat[1][0]\n    pos_labels = conf_mat[1][0]+conf_mat[1][1]\n    str_out += (\"{} out of {} positive labels ({:.4f}%)\\n\".format(fp, pos_labels,fp/pos_labels))\n    str_out += (\"\\n\")\n    str_out += (\"------------------------------------\\n\")\n\n    str_out += (\"FALSE NEGATIVES:\\n\")\n    fn = conf_mat[0][1]\n    neg_labels = conf_mat[0][1]+conf_mat[0][0]\n    str_out += (\"{} out of {} negative labels ({:.4f}%)\\n\".format(fn, neg_labels, fn/neg_labels))\n    str_out += (\"\\n\")\n    str_out += (\"------------------------------------\\n\")\n\n    #print classification report\n    str_out += (\"PRECISION, RECALL, F1 scores:\\n\\n\")\n    str_out += (\"{}\".format(classification_report(test, pred)))\n    \n    false_indexes = np.where(test != pred)\n    return str_out, false_indexes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classifier-1: Decision Tree CART","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# CART decision tree\ncart = DecisionTreeClassifier(random_state = 0)\n\n# parameters \nparameters = {\n                \"criterion\": [\"gini\",\"entropy\"],\n                \"splitter\": [\"best\",\"random\"],\n                \"class_weight\": [None, \"balanced\"],\n                }\n\n# grid search for parameters\ngrid_1 = GridSearchCV(estimator=cart, param_grid=parameters, cv=cv, n_jobs=-1)\ngrid_1.fit(X_train_final_df, y_train)\n\n# print best scores\nprint(\"The best parameters are %s with a score of %0.4f\"\n      % (grid_1.best_params_, grid_1.best_score_))\n\n# prediction results\ny_pred = grid_1.predict(X_test_final_df)\n\n# print accuracy metrics\nresults, false = display_test_scores(y_test, y_pred)\nprint(results)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classifier-2: Naive-Bayes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Naive-Bayes with different approaches\nnb_list = [ GaussianNB(), MultinomialNB(), ComplementNB()]\n\nfor nb in nb_list:\n    print(\"-----------\", str(nb), \"--------------\")\n    \n    # parameters \n    parameters = {}\n\n    # grid search for parameters\n    grid_2 = GridSearchCV(estimator=nb, param_grid=parameters, cv=cv, n_jobs=-1)\n    grid_2.fit(X_train_final_df, y_train)\n\n    # print best scores\n    print(\"The best parameters are %s with a score of %0.4f\\n\"\n          % (grid_2.best_params_, grid_2.best_score_))\n\n    # prediction results\n    y_pred = grid_2.predict(X_test_final_df)\n\n    # print accuracy metrics\n    results, false = display_test_scores(y_test, y_pred)\n    print(results)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classifier-3: SVM","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# SVM classifier\nsvm = SVC(tol=1e-5, random_state=0)\n\n# parameters \nparameters = {\n                'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n                'C': [0.01, 0.1, 1, 10, 100],\n                'max_iter': [100, 1000, 5000]\n            }\n\n# grid search for parameters\ngrid_3 = GridSearchCV(estimator=svm, param_grid=parameters, cv=cv, n_jobs=-1)\ngrid_3.fit(X_train_final_df, y_train)\n\n# print best scores\nprint(\"The best parameters are %s with a score of %0.4f\\n\"\n      % (grid_3.best_params_, grid_3.best_score_))\n\n# prediction results\ny_pred = grid_3.predict(X_test_final_df)\n\n# print accuracy metrics\nresults, false = display_test_scores(y_test, y_pred)\nprint(results)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classifier-4: kNN ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nknn = KNeighborsClassifier()\n# parameters \nparameters = {\n                \"algorithm\": [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"],\n                \"n_neighbors\": [5,15,25]\n    }\n\n# grid search for parameters\ngrid_4 = GridSearchCV(estimator=knn, param_grid=parameters, cv=cv, n_jobs=-1)\ngrid_4.fit(X_train_final_df, y_train)\n\n# print best scores\nprint(\"The best parameters are %s with a score of %0.4f\\n\"\n      % (grid_4.best_params_, grid_4.best_score_))\n\n# prediction results\ny_pred = grid_4.predict(X_test_final_df)\n\n# print accuracy metrics\nresults, false = display_test_scores(y_test, y_pred)\nprint(results)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classifier-5: Logistic Regression ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nlogit = LogisticRegression(random_state=0)\n# parameters \nparameters = {\n                \"penalty\":['l1', 'l2'],\n                \"C\": [0.01, 0.1, 1, 10, 100],\n                \"max_iter\": [100,1000,5000],\n             }\n\n# grid search for parameters\ngrid_5 = GridSearchCV(estimator=logit, param_grid=parameters, cv=cv, n_jobs=-1)\ngrid_5.fit(X_train_final_df, y_train)\n\n# print best scores\nprint(\"The best parameters are %s with a score of %0.4f\\n\"\n      % (grid_5.best_params_, grid_5.best_score_))\n\n# prediction results\ny_pred = grid_5.predict(X_test_final_df)\n\n# print accuracy metrics\nresults, false = display_test_scores(y_test, y_pred)\nprint(results)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classifier-6:RF","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nrf = RandomForestClassifier(random_state=0)\n\n# parameters \nparameters = {\n                \"bootstrap\": [\"True\",\"False\"],\n                \"max_features\": [None, \"sqrt\", \"log2\"],\n                \"class_weight\": [None, \"balanced\", \"balanced_subsample\"],\n                \"max_samples\": [None, 0.3, 0.5, 0.7, 0.9],\n                \"n_estimators\": [10, 100, 200]\n                \n}\n\n# grid search for parameters\ngrid_6 = GridSearchCV(estimator=rf, param_grid=parameters, cv=cv, n_jobs=-1)\ngrid_6.fit(X_train_final_df, y_train)\n\n# print best scores\nprint(\"The best parameters are %s with a score of %0.4f\"\n      % (grid_6.best_params_, grid_6.best_score_))\n\n# prediction results\ny_pred = grid_6.predict(X_test_final_df)\n\n# print accuracy metrics\nresults, false = display_test_scores(y_test, y_pred)\nprint(results)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classifier-7: Bagging Meta Estimator","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nfrom sklearn.ensemble import BaggingClassifier\n\nbag = BaggingClassifier(random_state=0)\n\n# parameters \nparameters = {\n                \"bootstrap\": [\"True\",\"False\"],\n                \"max_features\": [0.3, 0.5, 0.7, 0.9, 1],\n                \"max_samples\": [0.3, 0.5, 0.7, 0.9],\n                \"n_estimators\": [10, 100, 200]\n                \n}\n\n# grid search for parameters\ngrid_7 = GridSearchCV(estimator=bag, param_grid=parameters, cv=cv, n_jobs=-1)\ngrid_7.fit(X_train_final_df, y_train)\n\n# print best scores\nprint(\"The best parameters are %s with a score of %0.4f\"\n      % (grid_7.best_params_, grid_7.best_score_))\n\n# prediction results\ny_pred = grid_7.predict(X_test_final_df)\n\n# print accuracy metrics\nresults, false = display_test_scores(y_test, y_pred)\nprint(results)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classifier-8: ExtraTressClassifier ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.ensemble import ExtraTreesClassifier\n\nextra = ExtraTreesClassifier(random_state=0)\n\n# parameters \nparameters = {\n                \"bootstrap\": [\"True\",\"False\"],\n                \"max_features\": [None, \"sqrt\", \"log2\"],\n                \"class_weight\": [None, \"balanced\", \"balanced_subsample\"],\n                \"max_samples\": [None, 0.3, 0.5, 0.7, 0.9],\n                \"n_estimators\": [10, 100, 200]\n                \n}\n\n# grid search for parameters\ngrid_8 = GridSearchCV(estimator=extra, param_grid=parameters, cv=cv, n_jobs=-1)\ngrid_8.fit(X_train_final_df, y_train)\n\n# print best scores\nprint(\"The best parameters are %s with a score of %0.4f\"\n      % (grid_8.best_params_, grid_8.best_score_))\n\n# prediction results\ny_pred = grid_8.predict(X_test_final_df)\n\n# print accuracy metrics\nresults, false = display_test_scores(y_test, y_pred)\nprint(results)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}